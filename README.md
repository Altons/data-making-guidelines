# data-making-guidelines
documenting the DataMade ETL workflow

## DataMade's Data Making Principles

1. Never destroy data 
2. Ensure that each step in process is audit-able 
3. Be able to reproduce the final data with one command 
4. Write as little custom code as possible 
5. Use standard tools whenever possible 

## Implementation Specifics - Makefiles

To achieve a reproducible data workflow, we use GNU make

#### Introduction to make & makefiles
```make``` is a build tool that generates file *targets*, each of which can depend upon the existence of other files (*dependencies*). Targets, dependencies, and instructions specifying to build them are defined in a *makefile*.

```make``` is a particularly nifty tool for data processing because:
- because make targets have dependencies specified, make can build files in the right order
- make will not rebuild existing files if their dependencies haven't changed - make only builds what's necessary
- because make rules can be chained, all final data can be created with one command
- some more reasons

#### Makefile 101
The building block of a makefile is a "rule". Each "rule" specifies (1) a *target*, (2) the target's *dependencies*, and the target's *recipe* (i.e. the commands for creating the target).

The general structure of a single make "rule":
```
target: dependencies
[tab] recipe
```
**Targets** - the target is what you want to generate. it can be a the name of an output file, or a variable (more on this later)  
**Dependencies** - dependencies are optional. dependencies can be the names of files that need to exist in order to make the target, or variables (more on this later)  
**Recipes** - recipes are commands for generating the target file. any command you can run on the terminal is fair game  for recipes - bash commands, invoking a script, etc.  

[some content here about how make determines what to make & in what order, based on the rules & what files exist]

#### ETL workflow directory structure

[some notes on the directory structure, on top level makefile & sub makefiles]

```
|-- Makefile
|-- README.md
|-- data
|   |-- <group of files for processing>
|   |   |-- Makefile
|   |   |-- README.md # Gives details about the source of the data and about how
|   |   |             # it is processed by the pipeline
|   |   |-- build
|   |   |   `-- <temporary files generated by pipeline live here>
|   |   |-- finished_files
|   |   |   `-- <finished product of pipeline lives here>
|   |   |-- mid_process_files
|   |   |   `-- <mid-process files live here>
|   |   `-- raw
|   |       `-- <raw data files live here>
|   |-- <another group of files for processing>
|   |   `-- < ... etc ... >
|-- processors
|   |-- <processor_name>.py
|   `-- <another_processor_name>.sh
`-- requirements.txt # Lists requirements that need to be installed for pipeline
```

## Examples
- [Gary Counts](https://github.com/datamade/gary-counts-data)

## Related Links
- [Makefile Style Guide by Clark Grubb](http://clarkgrubb.com/makefile-style-guide#data-workflows)
- [Why Use Make by Mike Bostock](http://bost.ocks.org/mike/make/)
