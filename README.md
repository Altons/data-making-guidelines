# data-making-guidelines
documenting the DataMade ETL workflow

## DataMade's Data Making Principles

1. Never destroy data 
2. Ensure that each step in process is audit-able 
3. Be able to reproduce the final data with one command 
4. Write as little custom code as possible 
5. Use standard tools whenever possible 

## Implementation Specifics - Makefiles

To achieve a reproducible data workflow, we use GNU make

#### Introduction to make & makefiles
```make``` is a build tool that generates file *targets*, each of which can have *dependencies*. Targets, dependencies, and instructions specifying to build them are defined in a *makefile*.

```make``` is a particularly nifty tool for data processing because:
- a reason
- another reason

#### Makefile 101
The building block of a makefile is a "rule". Each "rule" specifies (1) a *target*, (2) the target's *dependencies*, and the target's *recipe* (i.e. the commands for creating the target).

The general structure of a single make "rule":
```
target: dependencies
[tab] recipe
```
**Targets** - some info
**Dependencies** - some info
**Recipes** - some info

[some content here about how make determines what to make & in what order, based on the rules & what files exist]

#### ETL workflow directory structure

[some notes on the directory structure, on top level makefile & sub makefiles]

```
|-- Makefile
|-- README.md
|-- data
|   |-- <group of files for processing>
|   |   |-- Makefile
|   |   |-- README.md # Gives details about the source of the data and about how
|   |   |             # it is processed by the pipeline
|   |   |-- build
|   |   |   `-- <temporary files generated by pipeline live here>
|   |   |-- finished_files
|   |   |   `-- <finished product of pipeline lives here>
|   |   |-- mid_process_files
|   |   |   `-- <mid-process files live here>
|   |   `-- raw
|   |       `-- <raw data files live here>
|   |-- <another group of files for processing>
|   |   `-- < ... etc ... >
|-- processors
|   |-- <processor_name>.py
|   `-- <another_processor_name>.sh
`-- requirements.txt # Lists requirements that need to be installed for pipeline
```

## Examples
- [Gary Counts](https://github.com/datamade/gary-counts-data)

## Related Links
- [Makefile Style Guide by Clark Grubb](http://clarkgrubb.com/makefile-style-guide#data-workflows)
